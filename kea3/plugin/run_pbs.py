import argparse
import logging
import os
import sys

import jinja2
from path import Path
# from xtermcolor import colorize as cz

import leip

from kea3.job import K3Job

lg = logging.getLogger('k3.run')

TEMPLATE = None
PBS_SUBMIT_SCRIPT_HEADER = """
#PBS -N {{ job_id }}
#PBS -S /bin/bash
#PBS -e {{ pbs_dir }}/{{ job_id }}.$PBS_JOBID.err
#PBS -o {{ pbs_dir }}/{{ job_id }}.$PBS_JOBID.out
#PBS -l walltime={{ pbs.walltime }}:00:00
#PBS -A {{ pbs.group }}{% if pbs.nodes %}
#PBS -l nodes={{pbs.nodes}}
    {%- if pbs.ppn %}:ppn={{pbs.ppn}}{% endif %}{% endif %}{%if pbs.mem %}
#PBS -l mem={{ pbs.mem }}{% endif %}

### this script is autogenerated by k3

### Display the job context
echo Running on host `hostname`
echo Time is `date`
echo Directory is `pwd`
echo Using ${NPROCS} processors across ${NNODES} nodes

set -v  # verbose output
set -e  # catch errors

{% if pyenv %}
#load python virtual environment
source {{ pyenv }}/bin/activate
{% endif %}

# make sure we're in the work directory
cd {{ cwd }}

## Starting jobs ({{ pbs.get('jobs_per_node', 1) }} per node)

""".lstrip()


class K3JobPbs(K3Job):
    def executor(self, cl: list) -> None:
        """
        execute a pbs job
        """

        self.app.cl_cache.append(cl)
        if len(self.app.cl_cache) >= self.ctx['pbs'].get('jobs_per_node', 1):
            self.run_flush()

    def get_header(self) -> str:

        self.ctx['cwd'] = os.getcwd()
        jobid = '%s.%s.%s' % (self.ctx['template']['name'], self.ctx['stamp'],
                              self.ctx['i'])

        self.ctx['job_id'] = jobid

        lg.info('pbs submit job: %s', jobid)

        self.pbs_script = self.ctx['pbs_dir'] / ('%s.qsub' %
                                                 self.ctx['job_id'])

        script = jinja2.Template(PBS_SUBMIT_SCRIPT_HEADER).render(self.ctx)
        return script

    def run_flush(self) -> None:

        script = self.get_header()

        for j in self.app.cl_cache:
            script += '(  '
            script += '\n   '.join(j)
            script += ' ) & \n\n'

        script += "wait\n\n"

        with open(self.pbs_script, 'w') as F:
            F.write(script)

        self.app.cl_cache = []
        if self.app.trans['args'].qsub:
            os.system('qsub %s' % self.pbs_script)
        else:
            print(str(Path(self.pbs_script).relpath()))


@leip.arg('arguments', nargs=argparse.REMAINDER)
@leip.flag('-d', '--dryrun', help='do not run')
@leip.flag('-q', '--qsub', help='actually qsub - otherwise write script files')
@leip.flag(
    '-B', '--always_run', dest='force', help='force run, regardless of checks')
@leip.arg('-n', '--jobstorun', help='no of jobs to run', type=int)
@leip.arg('-j',
          '--jobs-per-node',
          help='no of jobs to run in parallel per pbs job',
          type=int)
@leip.arg('-A', '--group', help='group to take pbs credits from')
@leip.arg('-W', '--walltime', help='walltime for the job (hours)')
@leip.arg('-M', '--mem', help='memory to request for the job')
@leip.arg('-N',
          '--nodes',
          help='no of nodes for the pbs job',
          type=int,
          default=1)
@leip.arg('-P', '--ppn', help='no of nodes for the pbs job', type=int)
@leip.arg('template')
@leip.command
def pbs(app, args):

    # first - maintain a run.sh script
    if ('-h' not in sys.argv) and ('--help' not in sys.argv):
        with open('run.sh', 'a') as F:
            F.write('# %s\n' % " ".join(sys.argv))

    job = K3JobPbs(app, args, args.template, args.arguments)
    app.cl_cache = []
    job.prepare()

    pbs_dir = (job.workdir / 'pbs').abspath()
    pbs_dir.makedirs_p()
    job.ctx['pbs_dir'] = pbs_dir
    job.ctx['pyenv'] = app.conf['pyenv']

    # make command line args available to the
    job.ctx['pbs'] = app.conf['pbs']  # sys conf
    job.ctx['pbs'].update(job.data['pbs'])  # job conf
    for akey in 'walltime nodes group mem'.split():
        if vars(args).get(akey):
            job.ctx['pbs'][akey] = vars(args)[akey]

    if not job.ctx['pbs']['walltime']:
        lg.error("Must specify a WALLTIME (-w N, with N in hours)")
        exit(-1)
    if not job.ctx['pbs']['group']:
        lg.error("Must specify an account group (-A groupname)")
        exit(-1)

    for k, v in vars(args).items():
        if v is not None:
            job.ctx['pbs'][k] = v

    # expand - generate a subjob for possible io/globs
    jobstorun = args.jobstorun

    for i, newjob in enumerate(job.expand()):
        newjob.run()
        if newjob.skipped and jobstorun:
            jobstorun += 1
        if jobstorun is not None and i + 1 >= jobstorun:
            break

    # make sure the last job gets run/written as well
    if len(app.cl_cache) > 0:
        newjob.run_flush()
